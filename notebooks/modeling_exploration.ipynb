{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f27ae527-2ee1-460b-957c-acfaff603b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37542 entries, 0 to 37541\n",
      "Data columns (total 25 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   id                            37542 non-null  object \n",
      " 1   listing_url                   37542 non-null  object \n",
      " 2   price                         37542 non-null  float64\n",
      " 3   property_type                 37542 non-null  object \n",
      " 4   room_type                     37542 non-null  object \n",
      " 5   neighborhood_overview         20892 non-null  object \n",
      " 6   bathrooms_text                37510 non-null  object \n",
      " 7   bedrooms                      37542 non-null  float64\n",
      " 8   beds                          37541 non-null  float64\n",
      " 9   accommodates                  37541 non-null  float64\n",
      " 10  latitude                      37541 non-null  float64\n",
      " 11  longitude                     37541 non-null  float64\n",
      " 12  neighbourhood_group_cleansed  37541 non-null  object \n",
      " 13  neighbourhood_cleansed        37541 non-null  object \n",
      " 14  neighborhood_overview.1       20891 non-null  object \n",
      " 15  description                   36221 non-null  object \n",
      " 16  amenities                     37541 non-null  object \n",
      " 17  host_about                    21294 non-null  object \n",
      " 18  review_scores_rating          37540 non-null  float64\n",
      " 19  review_scores_cleanliness     37540 non-null  float64\n",
      " 20  review_scores_checkin         37540 non-null  float64\n",
      " 21  review_scores_communication   37540 non-null  float64\n",
      " 22  review_scores_location        37540 non-null  float64\n",
      " 23  review_scores_value           37540 non-null  float64\n",
      " 24  number_of_reviews             37540 non-null  float64\n",
      "dtypes: float64(13), object(12)\n",
      "memory usage: 7.2+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tl/j82d5n7x3v35tkk6yfp87gfm0000gn/T/ipykernel_95823/905281789.py:9: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/arjunathreya/Projects/airbnb_similar_listings/ml/data/dataset/cleaned_listings.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display initial data information\n",
    "print(\"Initial Data Overview:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0507ade9-b887-4d1c-94e3-676903653813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                                description_summary\n",
      "0   739333866230665371  This 1-bedroom Private room in rental unit is ...\n",
      "1   572612125615500056  This 1-bedroom Private room in rental unit is ...\n",
      "2             45267941  This 1-bedroom Private room in rental unit is ...\n",
      "3   838141198693830649  This 3-bedroom Entire rental unit is located i...\n",
      "4  1082660771919357919  This 4-bedroom Entire home is located in South...\n",
      "This 1-bedroom Private room in rental unit is located in Fort Hamilton. The Private room accommodates 1 guests with 1 bed(s) and 1 shared bath. The price per night is $89.00. The property has a review rating of 4.7/5\n"
     ]
    }
   ],
   "source": [
    "def create_overview(row):\n",
    "    # Extract relevant fields\n",
    "    property_type = row['property_type']\n",
    "    room_type = row['room_type']\n",
    "    price = row['price']\n",
    "    bathrooms = row['bathrooms_text']\n",
    "    bedrooms = int(row['bedrooms']) if not pd.isnull(row['bedrooms']) else 'N/A'\n",
    "    beds = int(row['beds']) if not pd.isnull(row['beds']) else 'N/A'\n",
    "    accommodates = int(row['accommodates']) if not pd.isnull(row['accommodates']) else 'N/A'\n",
    "    neighborhood = row['neighbourhood_cleansed']\n",
    "    review_rating = row['review_scores_rating']\n",
    "    \n",
    "    # Construct the description\n",
    "    description_text = (\n",
    "        f\"This {bedrooms}-bedroom {property_type} is located in {neighborhood}. \"\n",
    "        f\"The {room_type} accommodates {accommodates} guests with {beds} bed(s) and \"\n",
    "        f\"{bathrooms}. \"\n",
    "    )\n",
    "    \n",
    "    # Adding price details\n",
    "    if not pd.isnull(price):\n",
    "        description_text += f\"The price per night is ${price:.2f}. \"\n",
    "\n",
    "    # Add review information if available\n",
    "    if not pd.isnull(review_rating):\n",
    "        description_text += (\n",
    "            f\"The property has a review rating of {review_rating:.1f}/5\"\n",
    "        )\n",
    "    \n",
    "    return description_text.strip()\n",
    "\n",
    "# Apply the function to the DataFrame and create a new column 'description_summary'\n",
    "df['description_summary'] = df.apply(create_overview, axis=1)\n",
    "\n",
    "# View the updated DataFrame with the new column\n",
    "print(df[['id', 'description_summary']].head())\n",
    "print(df['description_summary'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1fb5b0b-2d1b-4558-a494-4d9bd95cbee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                                   property_outline\n",
      "0   739333866230665371  Property Description: Lovely vocation room, ha...\n",
      "1   572612125615500056  Property Description: Cozy room in a charming ...\n",
      "2             45267941  Property Description: No detailed description ...\n",
      "3   838141198693830649  Property Description: No detailed description ...\n",
      "4  1082660771919357919  Property Description: 425 10th Street is what ...\n",
      "Property Description: Lovely vocation room, has work desk , tv, 2 windows , drawer, closet. Shared bathroom and kitchen. Kitchen includes everything a kitchen needs. Close to transportation and the park/ocean. Bars restaurants are walking distance 5 minutes Review Overview:• The property is consistently rated highly for cleanliness.• The check-in process is rated as smooth and easy by most guests.• The host is highly responsive and easy to communicate with.• The location is highly rated by guests, with many finding it convenient.• Guests believe the property offers excellent value for money.Overall, the reviews suggest that the property consistently meets or exceeds expectations.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_listing(row):\n",
    "    # Extract relevant fields\n",
    "    overall_rating = row['review_scores_rating']\n",
    "    cleanliness = row['review_scores_cleanliness']\n",
    "    checkin = row['review_scores_checkin']\n",
    "    communication = row['review_scores_communication']\n",
    "    location = row['review_scores_location']\n",
    "    value = row['review_scores_value']\n",
    "    description = row['description'] if not pd.isnull(row['description']) else \"No detailed description available.\"\n",
    "\n",
    "    # Start the outline with the property description\n",
    "    outline = f\"Property Description: {description} Review Overview:\"\n",
    "    \n",
    "    # Evaluate cleanliness\n",
    "    if cleanliness >= 4.5:\n",
    "        outline += \"• The property is consistently rated highly for cleanliness.\"\n",
    "    elif cleanliness >= 3.5:\n",
    "        outline += \"• The property is generally clean but could use some improvement.\"\n",
    "    else:\n",
    "        outline += \"• Cleanliness is often highlighted as a concern by guests.\"\n",
    "    \n",
    "    # Evaluate the check-in experience\n",
    "    if checkin >= 4.5:\n",
    "        outline += \"• The check-in process is rated as smooth and easy by most guests.\"\n",
    "    elif checkin >= 3.5:\n",
    "        outline += \"• The check-in process is generally okay, but there might be occasional issues.\"\n",
    "    else:\n",
    "        outline += \"• Guests frequently report issues with the check-in process.\"\n",
    "    \n",
    "    # Evaluate communication\n",
    "    if communication >= 4.5:\n",
    "        outline += \"• The host is highly responsive and easy to communicate with.\"\n",
    "    elif communication >= 3.5:\n",
    "        outline += \"• Communication with the host is generally fine, with some areas for improvement.\"\n",
    "    else:\n",
    "        outline += \"• Guests have often faced difficulties in communicating with the host.\"\n",
    "    \n",
    "    # Evaluate the location\n",
    "    if location >= 4.5:\n",
    "        outline += \"• The location is highly rated by guests, with many finding it convenient.\"\n",
    "    elif location >= 3.5:\n",
    "        outline += \"• The location is generally good but may not be ideal for everyone.\"\n",
    "    else:\n",
    "        outline += \"• The location might not be convenient or desirable for many guests.\"\n",
    "    \n",
    "    # Evaluate the value for money\n",
    "    if value >= 4.5:\n",
    "        outline += \"• Guests believe the property offers excellent value for money.\"\n",
    "    elif value >= 3.5:\n",
    "        outline += \"• The property offers reasonable value, though some guests may feel it's a bit pricey.\"\n",
    "    else:\n",
    "        outline += \"• Guests feel the property does not offer good value for the price.\"\n",
    "    \n",
    "    # Compare overall rating and scores\n",
    "    if (overall_rating >= 4.5 and cleanliness >= 4.5 and checkin >= 4.5 \n",
    "        and communication >= 4.5 and location >= 4.5 and value >= 4.5):\n",
    "        outline += \"Overall, the reviews suggest that the property consistently meets or exceeds expectations.\"\n",
    "    else:\n",
    "        outline += \"There are some areas where guest experiences may not fully align with the description, particularly in the aspects highlighted above.\"\n",
    "    \n",
    "    return outline\n",
    "\n",
    "# Apply the function to the DataFrame and create a new column 'property_outline'\n",
    "df['property_outline'] = df.apply(evaluate_listing, axis=1)\n",
    "\n",
    "# View the updated DataFrame with the new column\n",
    "print(df[['id', 'property_outline']].head())\n",
    "print(df['property_outline'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fb3d107-17cc-4e43-9987-1dbe4fdb2091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Private room in rental unit. Cozy room in a charming Sunset Park apartment. Room has a full bed (always) fresh sheets, 4 pillows, clothing rack, desk, nightstand, iron, towels, TV, air conditioning, free access to WiFi, shared kitchen and living room. Images have more details.<br /><br />Neighborhood has great spanish and asian restaurants. A short walk to Bay Ridge, wonderful middle eastern food. N/R Subway one block away. Close distance to the Bay Ridge Promenade & Industry City. <br />Cheers!<br />LGBT+\n",
      "id                                                             739333866230665371\n",
      "listing_url                       https://www.airbnb.com/rooms/739333866230665371\n",
      "price                                                                        89.0\n",
      "property_type                                         Private room in rental unit\n",
      "room_type                                                            Private room\n",
      "neighborhood_overview                                                         NaN\n",
      "bathrooms_text                                                      1 shared bath\n",
      "bedrooms                                                                      1.0\n",
      "beds                                                                          1.0\n",
      "accommodates                                                                  1.0\n",
      "latitude                                                                 40.61431\n",
      "longitude                                                               -74.03444\n",
      "neighbourhood_group_cleansed                                             Brooklyn\n",
      "neighbourhood_cleansed                                              Fort Hamilton\n",
      "neighborhood_overview.1                                                       NaN\n",
      "description                     Lovely vocation room, has work desk , tv, 2 wi...\n",
      "amenities                       [\"Kitchen\", \"Dedicated workspace\", \"TV\", \"Smok...\n",
      "host_about                                                                    NaN\n",
      "review_scores_rating                                                     4.725152\n",
      "review_scores_cleanliness                                                4.656433\n",
      "review_scores_checkin                                                    4.831447\n",
      "review_scores_communication                                              4.825776\n",
      "review_scores_location                                                   4.741619\n",
      "review_scores_value                                                      4.642455\n",
      "number_of_reviews                                                             0.0\n",
      "description_summary             This 1-bedroom Private room in rental unit is ...\n",
      "property_outline                Property Description: Lovely vocation room, ha...\n",
      "high_level_overview             This is a Private room in rental unit. Lovely ...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Sample function to construct a full description\n",
    "def construct_high_level_overview(row):\n",
    "    \"\"\"\n",
    "    Construct a full host description by combining property type, description, \n",
    "    and neighborhood overview.\n",
    "    :param row: A row from the DataFrame.\n",
    "    :return: A natural language description.\n",
    "    \"\"\"\n",
    "    # Start with property type\n",
    "    property_desc = f\"This is a {row['property_type']}.\"\n",
    "\n",
    "    # Add property description\n",
    "    if pd.notnull(row['description']):\n",
    "        property_desc += f\" {row['description']}\"\n",
    "    \n",
    "    # Add neighborhood overview if available\n",
    "    if pd.notnull(row['neighborhood_overview']):\n",
    "        property_desc += f\" The neighborhood is described as: {row['neighborhood_overview']}\"\n",
    "    \n",
    "    return property_desc\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df['high_level_overview'] = df.apply(construct_high_level_overview, axis=1)\n",
    "print(df['high_level_overview'].iloc[1])\n",
    "\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc3df767-2c92-470c-9eaa-4a75da268fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Batch Encoding: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [07:27<00:00,  2.62it/s]\n",
      "Batch Encoding: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [03:26<00:00,  5.70it/s]\n",
      "Batch Encoding:  10%|██████████████████▊                                                                                                                                                                      | 119/1174 [00:54<08:01,  2.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m df \u001b[38;5;241m=\u001b[39m generate_embeddings_with_progress(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty_outline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m df \u001b[38;5;241m=\u001b[39m generate_embeddings_with_progress(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription_summary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_embeddings_with_progress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhigh_level_overview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Function to compute weighted average of embeddings\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweighted_average_embedding\u001b[39m(embeddings, weights):\n",
      "Cell \u001b[0;32mIn[42], line 19\u001b[0m, in \u001b[0;36mgenerate_embeddings_with_progress\u001b[0;34m(df, column_name, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m     batch \u001b[38;5;241m=\u001b[39m df[column_name]\u001b[38;5;241m.\u001b[39miloc[i:i \u001b[38;5;241m+\u001b[39m batch_size]\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# Select a batch of texts\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     batch_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(batch, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Encode the batch\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mextend(\u001b[43mbatch_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Add embeddings to the list\u001b[39;00m\n\u001b[1;32m     21\u001b[0m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m embeddings\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the Sentence Transformer model\n",
    "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens') \n",
    "\n",
    "# for m1 mac\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Function to generate embeddings in batches with a progress bar\n",
    "def generate_embeddings_with_progress(df, column_name, batch_size=32):\n",
    "    embeddings = []\n",
    "    tqdm.pandas(desc=f\"Generating embeddings for {column_name}\")  # Setup progress bar description\n",
    "\n",
    "    # Generate embeddings in batches\n",
    "    for i in tqdm(range(0, len(df), batch_size), desc=\"Batch Encoding\"):\n",
    "        batch = df[column_name].iloc[i:i + batch_size].tolist()  # Select a batch of texts\n",
    "        batch_embeddings = model.encode(batch, convert_to_tensor=True)  # Encode the batch\n",
    "        embeddings.extend(batch_embeddings.tolist())  # Add embeddings to the list\n",
    "\n",
    "    df[f'{column_name}_embedding'] = embeddings\n",
    "    return df\n",
    "\n",
    "# Generate embeddings for property_outline and description_summary\n",
    "df = generate_embeddings_with_progress(df, 'property_outline')\n",
    "df = generate_embeddings_with_progress(df, 'description_summary')\n",
    "df = generate_embeddings_with_progress(df, 'high_level_overview')\n",
    "\n",
    "# Function to compute weighted average of embeddings\n",
    "def weighted_average_embedding(embeddings, weights):\n",
    "    \"\"\"\n",
    "    Calculate the weighted average of a list of embeddings.\n",
    "    :param embeddings: A list of embeddings (each embedding should be a numpy array or list).\n",
    "    :param weights: A list of weights corresponding to each embedding.\n",
    "    :return: The weighted average embedding as a numpy array.\n",
    "    \"\"\"\n",
    "    # Convert the embeddings to numpy arrays\n",
    "    embeddings = [np.array(embedding) for embedding in embeddings]\n",
    "    \n",
    "    # Compute the weighted sum of embeddings\n",
    "    weighted_sum = np.sum([embedding * weight for embedding, weight in zip(embeddings, weights)], axis=0)\n",
    "    \n",
    "    # Normalize by dividing by the sum of the weights\n",
    "    weighted_avg_embedding = weighted_sum / np.sum(weights)\n",
    "    \n",
    "    return weighted_avg_embedding\n",
    "\n",
    "# Function to apply the weighted average embedding calculation for each row in the DataFrame\n",
    "def apply_weighted_average(df, weight_outline=0.5, weight_description=0.3, weight_overview=0.2):\n",
    "    \"\"\"\n",
    "    Apply weighted average embedding calculation for each row of the DataFrame.\n",
    "    :param df: DataFrame containing embeddings columns.\n",
    "    :param weight_outline: Weight for the 'property_outline_embedding'.\n",
    "    :param weight_description: Weight for the 'description_summary_embedding'.\n",
    "    :param weight_overview: Weight for the 'high_level_overview_embedding'.\n",
    "    :return: The DataFrame with a new column 'average_embedding'.\n",
    "    \"\"\"\n",
    "    weights = [weight_outline, weight_description, weight_overview]\n",
    "\n",
    "    # Progress bar for calculating average embeddings\n",
    "    tqdm.pandas(desc=\"Calculating weighted average embeddings\")\n",
    "    \n",
    "    # Apply the weighted average embedding calculation row by row\n",
    "    df['average_embedding'] = df.progress_apply(\n",
    "        lambda row: weighted_average_embedding(\n",
    "            [row['property_outline_embedding'], row['description_summary_embedding'], row['high_level_overview_embedding']],\n",
    "            weights\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to calculate the weighted average of embeddings\n",
    "df = apply_weighted_average(df, weight_outline=0.5, weight_description=0.3, weight_overview=0.2)\n",
    "\n",
    "# View the DataFrame with the new 'average_embedding' column\n",
    "print(df[['id', 'property_outline_embedding', 'description_summary_embedding', 'high_level_overview_embedding', 'average_embedding']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ce37636-edbd-41a6-a74a-ad5839b8952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/Users/arjunathreya/Projects/airbnb_similar_listings/notebooks/listing_embeddings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca5c277b-4add-498a-ae88-6a7a8277ccdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Threshold: 0.950, Min Samples: 2 -> Number of clusters: 2127\n",
      "Similarity Threshold: 0.945, Min Samples: 2 -> Number of clusters: 1985\n",
      "Similarity Threshold: 0.940, Min Samples: 2 -> Number of clusters: 1817\n",
      "Similarity Threshold: 0.935, Min Samples: 2 -> Number of clusters: 1655\n",
      "Similarity Threshold: 0.930, Min Samples: 2 -> Number of clusters: 1463\n",
      "                    id  cluster  \\\n",
      "0   739333866230665371        0   \n",
      "1   572612125615500056        1   \n",
      "2             45267941        2   \n",
      "3   838141198693830649        2   \n",
      "4  1082660771919357919       -1   \n",
      "\n",
      "                                 listings_in_cluster  \n",
      "0                     [739333866230665371, 33908121]  \n",
      "1                     [572612125615500056, 45690330]  \n",
      "2  [45267941, 838141198693830649, 53190949, 10202...  \n",
      "3  [45267941, 838141198693830649, 53190949, 10202...  \n",
      "4  [1082660771919357919, 13234457, 76008653636827...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Function to perform DBSCAN clustering on preprocessed data\n",
    "def perform_clustering_dbscan(valid_vectors_df, similarity_threshold, min_samples):\n",
    "    # Convert similarity threshold to DBSCAN's eps (epsilon) parameter \n",
    "    eps_value = 1 - similarity_threshold\n",
    "\n",
    "    # Initialize DBSCAN with specified parameters\n",
    "    db = DBSCAN(eps=eps_value, min_samples=min_samples, metric='cosine')\n",
    "    \n",
    "    # Fit the DBSCAN model and assign cluster labels\n",
    "    valid_vectors_df['cluster'] = db.fit_predict(np.stack(valid_vectors_df['average_embedding'].values))\n",
    "\n",
    "    # Extract the unique cluster labels\n",
    "    labels = valid_vectors_df['cluster']\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "    # Output the results of clustering\n",
    "    print(f\"Similarity Threshold: {similarity_threshold:.3f}, Min Samples: {min_samples} -> Number of clusters: {n_clusters}\")\n",
    "\n",
    "    # Create a mapping of cluster labels to listings\n",
    "    cluster_groups = valid_vectors_df.groupby('cluster')['id'].apply(list).reset_index(name='listings_in_cluster')\n",
    "    \n",
    "    # Merge the cluster groups back to the valid_vectors_df\n",
    "    valid_vectors_df = valid_vectors_df.merge(cluster_groups, on='cluster', how='left')\n",
    "\n",
    "    return valid_vectors_df\n",
    "\n",
    "\n",
    "min_samples = 2  # Define the minimum number of samples in a neighborhood for point classification\n",
    "\n",
    "# Assume `listing_df` is your existing DataFrame with the `average_embedding` column\n",
    "listing_df = ...  # Replace this with your actual DataFrame\n",
    "\n",
    "# Iterate over a range of similarity thresholds to find the optimal clustering configuration\n",
    "for threshold in np.arange(0.980, 0.800, -0.005):  # Adjust the range as needed\n",
    "    # Filter out rows with null embeddings\n",
    "    valid_vectors_df = df[df['average_embedding'].notnull()]\n",
    "    result_df = perform_clustering_dbscan(valid_vectors_df, threshold, min_samples)\n",
    "\n",
    "# Output the final DataFrame with clusters and their corresponding listings\n",
    "print(result_df[['id', 'cluster', 'listings_in_cluster']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3457e3c0-490e-4567-922b-126c8227fb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PCA...\n",
      "Performing HDBSCAN clustering...\n",
      "                    id  cluster  \\\n",
      "0   739333866230665371     2975   \n",
      "1   572612125615500056     1224   \n",
      "2             45267941       -1   \n",
      "3   838141198693830649     5692   \n",
      "4  1082660771919357919       -1   \n",
      "\n",
      "                                 listings_in_cluster  \n",
      "0                     [739333866230665371, 33908121]  \n",
      "1                     [572612125615500056, 45690330]  \n",
      "2  [45267941, 1082660771919357919, 10296660925320...  \n",
      "3  [838141198693830649, 1127753693824936309, 8651...  \n",
      "4  [45267941, 1082660771919357919, 10296660925320...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import hdbscan\n",
    "\n",
    "METRIC = 'euclidean'  # Metric used for HDBSCAN\n",
    "# Function to reduce dimensionality of vector data using PCA\n",
    "def apply_pca(valid_vectors_df, n_components):\n",
    "    \"\"\"\n",
    "    Apply PCA to reduce the dimensionality of the vector data.\n",
    "    :param valid_vectors_df: DataFrame containing the high-dimensional vectors.\n",
    "    :param n_components: Number of principal components to use for PCA.\n",
    "    :return: The dimensionality reduced data.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components = 'mle', svd_solver = 'full')\n",
    "    reduced_data = pca.fit_transform(np.stack(valid_vectors_df['average_embedding'].values))\n",
    "    return reduced_data\n",
    "\n",
    "# Function to perform clustering using HDBSCAN\n",
    "def perform_clustering_hdbscan(reduced_data):\n",
    "    \"\"\"\n",
    "    Perform clustering on the dimensionality reduced data using HDBSCAN.\n",
    "    :param reduced_data: The dimensionality reduced data.\n",
    "    :return: Cluster labels and the HDBSCAN clusterer object.\n",
    "    \"\"\"\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=2,\n",
    "        min_samples=1,\n",
    "        metric=METRIC,\n",
    "        cluster_selection_epsilon=0.0  # Use the updated epsilon configuration\n",
    "    )\n",
    "    labels = clusterer.fit_predict(reduced_data)\n",
    "    return labels, clusterer\n",
    "\n",
    "n_components = 10  # Adjust based on your needs\n",
    "    \n",
    "# Apply PCA to reduce dimensionality\n",
    "print(\"Applying PCA...\")\n",
    "reduced_data = apply_pca(df, n_components)\n",
    "\n",
    "# Perform HDBSCAN clustering\n",
    "print(\"Performing HDBSCAN clustering...\")\n",
    "labels, clusterer = perform_clustering_hdbscan(reduced_data)\n",
    "\n",
    "valid_vectors_df_pca = df\n",
    "# Add the cluster labels to the original DataFrame\n",
    "valid_vectors_df_pca['cluster'] = labels\n",
    "\n",
    "# Group listings by cluster\n",
    "cluster_groups = valid_vectors_df_pca.groupby('cluster')['id'].apply(list).reset_index(name='listings_in_cluster')\n",
    "\n",
    "# Merge cluster groups back to original DataFrame if needed\n",
    "valid_vectors_df_pca = valid_vectors_df_pca.merge(cluster_groups, on='cluster', how='left')\n",
    "\n",
    "# Output the results\n",
    "print(valid_vectors_df_pca[['id', 'cluster', 'listings_in_cluster']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b5ec4a-6bb8-4c75-9484-65faed969ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
